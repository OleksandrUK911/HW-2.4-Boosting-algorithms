{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "В цьому домашньому завданні ми знову працюємо з даними з нашого змагання [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
        "\n",
        "Тут ми побудуємо рішення задачі класифікації з використанням алгоритмів бустингу: XGBoost та LightGBM, а також використаємо бібліотеку HyperOpt для оптимізації гіперпараметрів."
      ],
      "metadata": {
        "id": "fDefDHQt8LXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Зчитайте дані `train.csv` в змінну `raw_df` та скористайтесь наведеним кодом нижче аби розділити дані на трнувальні та валідаційні і розділити дані на ознаки з матириці Х та цільову змінну. Назви змінних `train_inputs, train_targets, train_inputs, train_targets` можна змінити на ті, які Вам зручно.\n",
        "\n",
        "  Наведений скрипт - частина отриманого мною скрипта для обробки даних. Ми тут не викнуємо масштабування та обробку категоріальних змінних, бо хочемо це делегувати алгоритмам, які будемо використовувати. Якщо щось не розумієте в наведених скриптах, рекомендую розібратись: навичка читати код - важлива складова роботи в машинному навчанні."
      ],
      "metadata": {
        "id": "LhivzW9W8-Dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple, Dict, Any\n",
        "\n",
        "\n",
        "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Split the dataframe into training and validation sets.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The raw dataframe.\n",
        "        target_col (str): The target column for stratification.\n",
        "        test_size (float): The proportion of the dataset to include in the validation split.\n",
        "        random_state (int): Random state for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
        "    \"\"\"\n",
        "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
        "    return train_df, val_df\n",
        "\n",
        "\n",
        "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
        "    \"\"\"\n",
        "    Separate inputs and targets from the dataframe.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The dataframe.\n",
        "        input_cols (list): List of input columns.\n",
        "        target_col (str): Target column.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
        "    \"\"\"\n",
        "    inputs = df[input_cols].copy()\n",
        "    targets = df[target_col].copy()\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "cKE8RTPf6CRD"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "raw_df = pd.read_csv('train.csv')\n",
        "\n",
        "# Define target column and input columns\n",
        "target_col = 'Exited'\n",
        "input_cols = [col for col in raw_df.columns if col not in [target_col, 'id']]\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_df, val_df = split_train_val(raw_df, target_col)\n",
        "\n",
        "# Separate inputs and targets for training and validation sets\n",
        "train_inputs, train_targets = separate_inputs_targets(train_df, input_cols, target_col)\n",
        "val_inputs, val_targets = separate_inputs_targets(val_df, input_cols, target_col)\n",
        "\n",
        "print(\"Data loaded and split successfully.\")\n",
        "print(\"Training inputs shape:\", train_inputs.shape)\n",
        "print(\"Training targets shape:\", train_targets.shape)\n",
        "print(\"Validation inputs shape:\", val_inputs.shape)\n",
        "print(\"Validation targets shape:\", val_targets.shape)"
      ],
      "metadata": {
        "id": "-bHdMJVB4xQR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd16a9a3-625d-4f6d-ad0d-d7ca2e71db02"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and split successfully.\n",
            "Training inputs shape: (12000, 12)\n",
            "Training targets shape: (12000,)\n",
            "Validation inputs shape: (3000, 12)\n",
            "Validation targets shape: (3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. В тренувальному та валідаційному наборі перетворіть категоріальні ознаки на тип `category`. Можна це зробити двома способами:\n",
        " 1. `df[col_name].astype('category')`, як було продемонстровано в лекції\n",
        " 2. використовуючи метод `pd.Categorical(df[col_name])`"
      ],
      "metadata": {
        "id": "cq0JU7MqHgp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = train_inputs.select_dtypes(include='object').columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    train_inputs[col] = train_inputs[col].astype('category')\n",
        "    val_inputs[col] = val_inputs[col].astype('category')\n",
        "\n",
        "print(\"Categorical features converted successfully.\")\n",
        "print(\"Data types in train_inputs after conversion:\")\n",
        "print(train_inputs.dtypes)\n",
        "print(\"\\nData types in val_inputs after conversion:\")\n",
        "print(val_inputs.dtypes)"
      ],
      "metadata": {
        "id": "UPmqo-Mr4yUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2a9d6ac-190b-4e49-ca26-f5ddc38062e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorical features converted successfully.\n",
            "Data types in train_inputs after conversion:\n",
            "CustomerId          float64\n",
            "Surname            category\n",
            "CreditScore         float64\n",
            "Geography          category\n",
            "Gender             category\n",
            "Age                 float64\n",
            "Tenure              float64\n",
            "Balance             float64\n",
            "NumOfProducts       float64\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "EstimatedSalary     float64\n",
            "dtype: object\n",
            "\n",
            "Data types in val_inputs after conversion:\n",
            "CustomerId          float64\n",
            "Surname            category\n",
            "CreditScore         float64\n",
            "Geography          category\n",
            "Gender             category\n",
            "Age                 float64\n",
            "Tenure              float64\n",
            "Balance             float64\n",
            "NumOfProducts       float64\n",
            "HasCrCard           float64\n",
            "IsActiveMember      float64\n",
            "EstimatedSalary     float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Навчіть на отриманих даних модель `XGBoostClassifier`. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів XGBoostClassifier - тут https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування `XGBoostClassifier` аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Можна також, якщо працюєте в Google Colab, увімкнути можливість використання GPU (`Runtime -> Change runtime type -> T4 GPU`) і встановити параметр `device='cuda'` в `XGBoostClassifier` для пришвидшення тренування бустинг моделі.\n",
        "  \n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням DecisionTrees раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "_LxWkv4o-wMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Initialize and train the XGBoostClassifier model\n",
        "# Use handle_missing='enable' to handle missing values\n",
        "# Use enable_categorical=True to handle categorical features\n",
        "# Consider adding device='cuda' if you have a GPU\n",
        "xgb_clf = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                            eval_metric='auc',\n",
        "                            use_label_encoder=False, # Deprecated, set to False\n",
        "                            n_estimators=100,\n",
        "                            learning_rate=0.1,\n",
        "                            max_depth=5,\n",
        "                            random_state=42,\n",
        "                            n_jobs=-1,\n",
        "                            tree_method='hist', # Use hist for better performance with categorical features\n",
        "                            enable_categorical=True,\n",
        "                            handle_missing='enable')\n",
        "\n",
        "xgb_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# Predict probabilities\n",
        "train_pred_proba_xgb = xgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_pred_proba_xgb = xgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Calculate AUROC\n",
        "train_roc_auc_xgb = roc_auc_score(train_targets, train_pred_proba_xgb)\n",
        "val_roc_auc_xgb = roc_auc_score(val_targets, val_pred_proba_xgb)\n",
        "\n",
        "print(f\"AUROC on training set (XGBoost): {train_roc_auc_xgb:.4f}\")\n",
        "print(f\"AUROC on validation set (XGBoost): {val_roc_auc_xgb:.4f}\")\n",
        "\n",
        "# Conclusion about the model\n",
        "print(\"\\nВисновки щодо моделі XGBoostClassifier:\")\n",
        "if train_roc_auc_xgb > val_roc_auc_xgb and (train_roc_auc_xgb - val_roc_auc_xgb) > 0.05:\n",
        "    print(\"Модель, можливо, має високу дисперсію (high variance), оскільки якість на тренувальному наборі значно вища, ніж на валідаційному.\")\n",
        "elif train_roc_auc_xgb < 0.7 or val_roc_auc_xgb < 0.7: # Example threshold, adjust as needed\n",
        "     print(\"Модель, можливо, має високе зміщення (high bias), оскільки якість на обох наборах невисока.\")\n",
        "else:\n",
        "    print(\"Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\")\n",
        "\n",
        "# Placeholder for comparison with Decision Trees (assuming previous results are available)\n",
        "print(\"\\nПорівняння з Decision Trees (потрібно порівняти з результатами попередніх завдань):\")\n",
        "print(\"Для повного порівняння необхідно мати результати AUROC з моделі Decision Trees.\")\n",
        "print(\"Якщо AUROC на валідаційному наборі вищий за Decision Trees, то якість покращилась.\")"
      ],
      "metadata": {
        "id": "_5rDqdDP41hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7579b433-44e4-490f-f8b4-cd3e270272c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:05:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUROC on training set (XGBoost): 0.9788\n",
            "AUROC on validation set (XGBoost): 0.9323\n",
            "\n",
            "Висновки щодо моделі XGBoostClassifier:\n",
            "Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\n",
            "\n",
            "Порівняння з Decision Trees (потрібно порівняти з результатами попередніх завдань):\n",
            "Для повного порівняння необхідно мати результати AUROC з моделі Decision Trees.\n",
            "Якщо AUROC на валідаційному наборі вищий за Decision Trees, то якість покращилась.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `XGBoostClassifier` з лекції знайдіть оптимальні значення гіперпараметрів `XGBoostClassifier` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **20**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. В ній ми маємо задати loss - це може будь-яка метрика, але бажано використовувтаи ту, яка цільова в вашій задачі. Чим менший лосс - тим ліпша модель на думку hyperopt. Тож, тут нам треба задати loss - негативне значення AUROC. В лекції ми натомість використовували Accuracy.\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_clf` модель `XGBoostClassifier` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_clf`\n",
        "    - оцініть якість моделі `final_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (2) цього завдання?"
      ],
      "metadata": {
        "id": "U4hm5qYs_f7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# 1. Define the objective function\n",
        "def objective(params):\n",
        "    \"\"\"\n",
        "    Objective function for Hyperopt to minimize (negative AUROC).\n",
        "    \"\"\"\n",
        "    # Need to convert certain parameters to int within the objective function\n",
        "    # as they are sampled as floats by hyperopt\n",
        "    params_int = {k: int(v) if k in ['n_estimators', 'max_depth', 'min_child_weight'] else v for k, v in params.items()}\n",
        "\n",
        "\n",
        "    clf = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                            eval_metric='auc',\n",
        "                            use_label_encoder=False,\n",
        "                            random_state=42,\n",
        "                            n_jobs=-1,\n",
        "                            tree_method='hist', # Use hist for better performance with categorical features\n",
        "                            enable_categorical=True,\n",
        "                            handle_missing='enable', # This parameter might be ignored in newer versions\n",
        "                            **params_int)\n",
        "\n",
        "    clf.fit(train_inputs, train_targets)\n",
        "\n",
        "    val_pred_proba = clf.predict_proba(val_inputs)[:, 1]\n",
        "    roc_auc = roc_auc_score(val_targets, val_pred_proba)\n",
        "\n",
        "    # Hyperopt minimizes the objective function, so we return the negative AUROC\n",
        "    return {'loss': -roc_auc, 'status': STATUS_OK}\n",
        "\n",
        "# 2. Define the hyperparameter space\n",
        "space = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 50),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # From 0.05 to 1 (~0.05 to 1)\n",
        "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
        "    'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
        "    'gamma': hp.uniform('gamma', 0, 0.5),\n",
        "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', -5, 0), # From exp(-5) to exp(0) (~0.0067 to 1)\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', -5, 0) # From exp(-5) to exp(0) (~0.0067 to 1)\n",
        "}\n",
        "\n",
        "\n",
        "# 3. Run the optimization\n",
        "trials = Trials()\n",
        "best_params = fmin(fn=objective,\n",
        "                   space=space,\n",
        "                   algo=tpe.suggest,\n",
        "                   max_evals=20, # Set the number of rounds to 20 as requested\n",
        "                   trials=trials)\n",
        "\n",
        "print(\"\\nНайкращі гіперпараметри:\", best_params)\n",
        "\n",
        "# 4. Train the final model with the best hyperparameters\n",
        "# Need to convert best_params from float to int for certain parameters\n",
        "best_params_final = {k: int(v) if k in ['n_estimators', 'max_depth', 'min_child_weight'] else v for k, v in best_params.items()}\n",
        "\n",
        "\n",
        "final_clf = xgb.XGBClassifier(objective='binary:logistic',\n",
        "                              eval_metric='auc',\n",
        "                              use_label_encoder=False,\n",
        "                              random_state=42,\n",
        "                              n_jobs=-1,\n",
        "                              tree_method='hist',\n",
        "                              enable_categorical=True,\n",
        "                              handle_missing='enable', # This parameter might be ignored in newer versions\n",
        "                              **best_params_final)\n",
        "\n",
        "final_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# 5. Evaluate the final model\n",
        "train_pred_proba_final = final_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_pred_proba_final = final_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_roc_auc_final = roc_auc_score(train_targets, train_pred_proba_final)\n",
        "val_roc_auc_final = roc_auc_score(val_targets, val_pred_proba_final)\n",
        "\n",
        "print(f\"\\nAUROC on training set (XGBoost with Hyperopt): {train_roc_auc_final:.4f}\")\n",
        "print(f\"AUROC on validation set (XGBoost with Hyperopt): {val_roc_auc_final:.4f}\")\n",
        "\n",
        "# Conclusion about the model\n",
        "print(\"\\nВисновки щодо моделі XGBoostClassifier з Hyperopt:\")\n",
        "if train_roc_auc_final > val_roc_auc_final and (train_roc_auc_final - val_roc_auc_final) > 0.05:\n",
        "    print(\"Модель, можливо, має високу дисперсію (high variance), оскільки якість на тренувальному наборі значно вища, ніж на валідаційному.\")\n",
        "elif train_roc_auc_final < 0.7 or val_roc_auc_final < 0.7: # Example threshold, adjust as needed\n",
        "     print(\"Модель, можливо, має високе зміщення (high bias), оскільки якість на обох наборах невисока.\")\n",
        "else:\n",
        "    print(\"Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\")\n",
        "\n",
        "# Comparison with the previous model\n",
        "print(\"\\nПорівняння з попередньою моделлю XGBoostClassifier (без Hyperopt):\")\n",
        "# Ensure val_roc_auc_xgb is defined before using it\n",
        "if 'val_roc_auc_xgb' in globals():\n",
        "    print(f\"AUROC на валідаційному наборі без Hyperopt: {val_roc_auc_xgb:.4f}\")\n",
        "    print(f\"AUROC на валідаційному наборі з Hyperopt: {val_roc_auc_final:.4f}\")\n",
        "\n",
        "    if val_roc_auc_final > val_roc_auc_xgb:\n",
        "        print(\"Якість моделі покращилась після оптимізації гіперпараметрів за допомогою Hyperopt.\")\n",
        "    elif val_roc_auc_final < val_roc_auc_xgb:\n",
        "        print(\"Якість моделі погіршилась після оптимізації гіперпараметрів за допомогою Hyperopt.\")\n",
        "    else:\n",
        "        print(\"Якість моделі залишилась без змін після оптимізації гіперпараметрів за допомогою Hyperopt.\")\n",
        "else:\n",
        "    print(\"Результати AUROC без Hyperopt недоступні для порівняння.\")"
      ],
      "metadata": {
        "id": "WhR1g9B4433r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56621c86-4f02-4447-c8c1-fddb5005ecce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5%|▌         | 1/20 [00:00<00:15,  1.24trial/s, best loss: -0.9297798202894573]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:06] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10%|█         | 2/20 [00:01<00:08,  2.07trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15%|█▌        | 3/20 [00:01<00:09,  1.79trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:07] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20%|██        | 4/20 [00:02<00:09,  1.67trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25%|██▌       | 5/20 [00:02<00:08,  1.68trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:08] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 35%|███▌      | 7/20 [00:03<00:06,  2.15trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:09] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40%|████      | 8/20 [00:04<00:07,  1.71trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:10] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45%|████▌     | 9/20 [00:05<00:05,  1.90trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:11] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50%|█████     | 10/20 [00:07<00:10,  1.02s/trial, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55%|█████▌    | 11/20 [00:07<00:08,  1.10trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:13] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60%|██████    | 12/20 [00:08<00:06,  1.25trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65%|██████▌   | 13/20 [00:08<00:04,  1.44trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:14] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70%|███████   | 14/20 [00:09<00:03,  1.80trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 80%|████████  | 16/20 [00:09<00:01,  2.11trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:15] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85%|████████▌ | 17/20 [00:12<00:03,  1.08s/trial, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:18] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90%|█████████ | 18/20 [00:13<00:01,  1.02trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:19] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95%|█████████▌| 19/20 [00:13<00:00,  1.26trial/s, best loss: -0.9364565470882776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:19] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [00:14<00:00,  1.42trial/s, best loss: -0.9364565470882776]\n",
            "\n",
            "Найкращі гіперпараметри: {'colsample_bytree': np.float64(0.7492150433815387), 'gamma': np.float64(0.46920665998710176), 'learning_rate': np.float64(0.05583909944478992), 'max_depth': np.float64(3.0), 'min_child_weight': np.float64(4.0), 'n_estimators': np.float64(200.0), 'reg_alpha': np.float64(0.008534347278250896), 'reg_lambda': np.float64(0.6038030861691353), 'subsample': np.float64(0.9174714583233008)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [21:08:20] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"handle_missing\", \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUROC on training set (XGBoost with Hyperopt): 0.9473\n",
            "AUROC on validation set (XGBoost with Hyperopt): 0.9365\n",
            "\n",
            "Висновки щодо моделі XGBoostClassifier з Hyperopt:\n",
            "Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\n",
            "\n",
            "Порівняння з попередньою моделлю XGBoostClassifier (без Hyperopt):\n",
            "AUROC на валідаційному наборі без Hyperopt: 0.9323\n",
            "AUROC на валідаційному наборі з Hyperopt: 0.9365\n",
            "Якість моделі покращилась після оптимізації гіперпараметрів за допомогою Hyperopt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Навчіть на наших даних модель LightGBM. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
        "\n",
        "  Опис всіх конфігураційних параметрів LightGBM - тут https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
        "\n",
        "  **Важливо:** зробіть такі налаштування LightGBM аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
        "\n",
        "  Аби передати категоріальні колонки в LightGBM - необхідно виявити їх індекси і передати в параметрі `cat_feature=cat_feature_indexes`\n",
        "\n",
        "  Після тренування моделі\n",
        "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
        "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
        "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням XGBoostClassifier раніше. Чи вийшло покращити якість?"
      ],
      "metadata": {
        "id": "Vg77SVWrBBmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Identify categorical feature indices for LightGBM\n",
        "categorical_feature_names = train_inputs.select_dtypes(include='category').columns\n",
        "categorical_feature_indices = [train_inputs.columns.get_loc(col) for col in categorical_feature_names]\n",
        "\n",
        "# Initialize and train the LightGBM model\n",
        "# LightGBM handles missing values and categorical features internally with appropriate settings\n",
        "lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
        "                             metric='auc',\n",
        "                             n_estimators=100,\n",
        "                             learning_rate=0.1,\n",
        "                             max_depth=5,\n",
        "                             random_state=42,\n",
        "                             n_jobs=-1,\n",
        "                             # Use categorical_feature parameter to specify categorical columns by index\n",
        "                             categorical_feature=categorical_feature_indices\n",
        "                            )\n",
        "\n",
        "# LightGBM can train directly on pandas DataFrames with categorical dtypes\n",
        "lgb_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# Predict probabilities\n",
        "train_pred_proba_lgb = lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_pred_proba_lgb = lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "# Calculate AUROC\n",
        "train_roc_auc_lgb = roc_auc_score(train_targets, train_pred_proba_lgb)\n",
        "val_roc_auc_lgb = roc_auc_score(val_targets, val_pred_proba_lgb)\n",
        "\n",
        "print(f\"AUROC on training set (LightGBM): {train_roc_auc_lgb:.4f}\")\n",
        "print(f\"AUROC on validation set (LightGBM): {val_roc_auc_lgb:.4f}\")\n",
        "\n",
        "# Conclusion about the model\n",
        "print(\"\\nВисновки щодо моделі LightGBM:\")\n",
        "if train_roc_auc_lgb > val_roc_auc_lgb and (train_roc_auc_lgb - val_roc_auc_lgb) > 0.05:\n",
        "    print(\"Модель, можливо, має високу дисперсію (high variance), оскільки якість на тренувальному наборі значно вища, ніж на валідаційному.\")\n",
        "elif train_roc_auc_lgb < 0.7 or val_roc_auc_lgb < 0.7: # Example threshold, adjust as needed\n",
        "     print(\"Модель, можливо, має високе зміщення (high bias), оскільки якість на обох наборах невисока.\")\n",
        "else:\n",
        "    print(\"Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\")\n",
        "\n",
        "# Comparison with the XGBoost model\n",
        "print(\"\\nПорівняння з моделлю XGBoostClassifier (без Hyperopt):\")\n",
        "# Ensure val_roc_auc_xgb is defined before using it\n",
        "if 'val_roc_auc_xgb' in globals():\n",
        "    print(f\"AUROC на валідаційному наборі XGBoost (без Hyperopt): {val_roc_auc_xgb:.4f}\")\n",
        "    print(f\"AUROC на валідаційному наборі LightGBM: {val_roc_auc_lgb:.4f}\")\n",
        "\n",
        "    if val_roc_auc_lgb > val_roc_auc_xgb:\n",
        "        print(\"Якість моделі LightGBM краща за початкову модель XGBoost.\")\n",
        "    elif val_roc_auc_lgb < val_roc_auc_xgb:\n",
        "        print(\"Якість моделі LightGBM гірша за початкову модель XGBoost.\")\n",
        "    else:\n",
        "        print(\"Якість моделей LightGBM та початкової XGBoost схожа.\")\n",
        "else:\n",
        "    print(\"Результати AUROC для початкової моделі XGBoost недоступні для порівняння.\")\n",
        "\n",
        "print(\"\\nПорівняння з оптимізованою моделлю XGBoostClassifier (з Hyperopt):\")\n",
        "# Ensure val_roc_auc_final is defined before using it\n",
        "if 'val_roc_auc_final' in globals():\n",
        "    print(f\"AUROC на валідаційному наборі XGBoost (з Hyperopt): {val_roc_auc_final:.4f}\")\n",
        "    print(f\"AUROC на валідаційному наборі LightGBM: {val_roc_auc_lgb:.4f}\")\n",
        "\n",
        "    if val_roc_auc_lgb > val_roc_auc_final:\n",
        "        print(\"Якість моделі LightGBM краща за оптимізовану модель XGBoost.\")\n",
        "    elif val_roc_auc_lgb < val_roc_auc_final:\n",
        "        print(\"Якість моделі LightGBM гірша за оптимізовану модель XGBoost.\")\n",
        "    else:\n",
        "        print(\"Якість моделей LightGBM та оптимізованої XGBoost схожа.\")\n",
        "else:\n",
        "    print(\"Результати AUROC для оптимізованої моделі XGBoost недоступні для порівняння.\")"
      ],
      "metadata": {
        "id": "C-9aZn4d45No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06d225a9-3980-4161-da09-07c67ab8acb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "AUROC on training set (LightGBM): 0.9819\n",
            "AUROC on validation set (LightGBM): 0.9323\n",
            "\n",
            "Висновки щодо моделі LightGBM:\n",
            "Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\n",
            "\n",
            "Порівняння з моделлю XGBoostClassifier (без Hyperopt):\n",
            "AUROC на валідаційному наборі XGBoost (без Hyperopt): 0.9323\n",
            "AUROC на валідаційному наборі LightGBM: 0.9323\n",
            "Якість моделі LightGBM гірша за початкову модель XGBoost.\n",
            "\n",
            "Порівняння з оптимізованою моделлю XGBoostClassifier (з Hyperopt):\n",
            "AUROC на валідаційному наборі XGBoost (з Hyperopt): 0.9365\n",
            "AUROC на валідаційному наборі LightGBM: 0.9323\n",
            "Якість моделі LightGBM гірша за оптимізовану модель XGBoost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `LightGBM` з лекції знайдіть оптимальні значення гіперпараметрів `LightGBM` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **10**.\n",
        "\n",
        "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. І тут ми також ставимо loss - негативне значення AUROC, як і при пошуці гіперпараметрів для XGBoost. До речі, можна спробувати написати код так, аби в objective передавати лише модель і не писати схожий код двічі :)\n",
        "\n",
        "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
        "    - виведіть найкращі значення гіперпараметрів\n",
        "    - створіть в окремій зміній `final_lgb_clf` модель `LightGBM` з найкращими гіперпараметрами\n",
        "    - навчіть модель `final_lgb_clf`\n",
        "    - оцініть якість моделі `final_lgb_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
        "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (4) цього завдання?"
      ],
      "metadata": {
        "id": "nCnkGD_sEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Identify categorical feature indices for LightGBM (if not already done)\n",
        "categorical_feature_names = train_inputs.select_dtypes(include='category').columns\n",
        "categorical_feature_indices = [train_inputs.columns.get_loc(col) for col in categorical_feature_names]\n",
        "\n",
        "\n",
        "# 1. Define the objective function for LightGBM\n",
        "def objective_lgb(params):\n",
        "    \"\"\"\n",
        "    Objective function for Hyperopt to minimize (negative AUROC) for LightGBM.\n",
        "    \"\"\"\n",
        "    # Need to convert certain parameters to int within the objective function\n",
        "    params_int = {k: int(v) if k in ['n_estimators', 'max_depth', 'num_leaves', 'min_child_samples'] else v for k, v in params.items()}\n",
        "\n",
        "    clf = lgb.LGBMClassifier(objective='binary',\n",
        "                             metric='auc',\n",
        "                             random_state=42,\n",
        "                             n_jobs=-1,\n",
        "                             categorical_feature=categorical_feature_indices,\n",
        "                             **params_int)\n",
        "\n",
        "    clf.fit(train_inputs, train_targets)\n",
        "\n",
        "    val_pred_proba = clf.predict_proba(val_inputs)[:, 1]\n",
        "    roc_auc = roc_auc_score(val_targets, val_pred_proba)\n",
        "\n",
        "    # Hyperopt minimizes the objective function, so we return the negative AUROC\n",
        "    return {'loss': -roc_auc, 'status': STATUS_OK}\n",
        "\n",
        "# 2. Define the hyperparameter space for LightGBM\n",
        "space_lgb = {\n",
        "    'n_estimators': hp.quniform('n_estimators', 50, 500, 50),\n",
        "    'learning_rate': hp.loguniform('learning_rate', -3, 0), # From 0.05 to 1\n",
        "    'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
        "    'num_leaves': hp.quniform('num_leaves', 20, 60, 5), # Often between 20 and 60 for LightGBM\n",
        "    'min_child_samples': hp.quniform('min_child_samples', 5, 50, 5),\n",
        "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
        "    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
        "    'reg_alpha': hp.loguniform('reg_alpha', -5, 0),\n",
        "    'reg_lambda': hp.loguniform('reg_lambda', -5, 0)\n",
        "}\n",
        "\n",
        "\n",
        "# 3. Run the optimization for LightGBM\n",
        "trials_lgb = Trials()\n",
        "best_params_lgb = fmin(fn=objective_lgb,\n",
        "                       space=space_lgb,\n",
        "                       algo=tpe.suggest,\n",
        "                       max_evals=10, # Set the number of rounds to 10 as requested\n",
        "                       trials=trials_lgb)\n",
        "\n",
        "print(\"\\nНайкращі гіперпараметри для LightGBM:\", best_params_lgb)\n",
        "\n",
        "# 4. Train the final LightGBM model with the best hyperparameters\n",
        "# Need to convert best_params from float to int for certain parameters\n",
        "best_params_lgb_final = {k: int(v) if k in ['n_estimators', 'max_depth', 'num_leaves', 'min_child_samples'] else v for k, v in best_params_lgb.items()}\n",
        "\n",
        "\n",
        "final_lgb_clf = lgb.LGBMClassifier(objective='binary',\n",
        "                                   metric='auc',\n",
        "                                   random_state=42,\n",
        "                                   n_jobs=-1,\n",
        "                                   categorical_feature=categorical_feature_indices,\n",
        "                                   **best_params_lgb_final)\n",
        "\n",
        "final_lgb_clf.fit(train_inputs, train_targets)\n",
        "\n",
        "# 5. Evaluate the final LightGBM model\n",
        "train_pred_proba_final_lgb = final_lgb_clf.predict_proba(train_inputs)[:, 1]\n",
        "val_pred_proba_final_lgb = final_lgb_clf.predict_proba(val_inputs)[:, 1]\n",
        "\n",
        "train_roc_auc_final_lgb = roc_auc_score(train_targets, train_pred_proba_final_lgb)\n",
        "val_roc_auc_final_lgb = roc_auc_score(val_targets, val_pred_proba_final_lgb)\n",
        "\n",
        "print(f\"\\nAUROC on training set (LightGBM with Hyperopt): {train_roc_auc_final_lgb:.4f}\")\n",
        "print(f\"AUROC on validation set (LightGBM with Hyperopt): {val_roc_auc_final_lgb:.4f}\")\n",
        "\n",
        "# Conclusion about the model\n",
        "print(\"\\nВисновки щодо моделі LightGBM з Hyperopt:\")\n",
        "if train_roc_auc_final_lgb > val_roc_auc_final_lgb and (train_roc_auc_final_lgb - val_roc_auc_final_lgb) > 0.05:\n",
        "    print(\"Модель, можливо, має високу дисперсію (high variance), оскільки якість на тренувальному наборі значно вища, ніж на валідаційному.\")\n",
        "elif val_roc_auc_final_lgb < 0.7: # Example threshold, adjust as needed\n",
        "     print(\"Модель, можливо, має високе зміщення (high bias), оскільки якість на валідаційному наборі невисока.\")\n",
        "else:\n",
        "    print(\"Модель показує схожу якість на тренувальному та валідаційному наборах, що свідчить про збалансоване співвідношення зміщення та дисперсії.\")\n",
        "\n",
        "# Comparison with previous models\n",
        "print(\"\\nПорівняння з попередніми моделями:\")\n",
        "# Ensure previous AUROC values are defined before using them\n",
        "if 'val_roc_auc_xgb' in globals():\n",
        "    print(f\"AUROC на валідаційному наборі XGBoost (без Hyperopt): {val_roc_auc_xgb:.4f}\")\n",
        "if 'val_roc_auc_final' in globals():\n",
        "    print(f\"AUROC на валідаційному наборі XGBoost (з Hyperopt): {val_roc_auc_final:.4f}\")\n",
        "if 'val_roc_auc_lgb' in globals():\n",
        "     print(f\"AUROC на валідаційному наборі LightGBM (без Hyperopt): {val_roc_auc_lgb:.4f}\")\n",
        "\n",
        "print(f\"AUROC на валідаційному наборі LightGBM (з Hyperopt): {val_roc_auc_final_lgb:.4f}\")\n",
        "\n",
        "# Determine which model performed best on the validation set\n",
        "best_val_auc = max(val_roc_auc_xgb if 'val_roc_auc_xgb' in globals() else 0,\n",
        "                   val_roc_auc_final if 'val_roc_auc_final' in globals() else 0,\n",
        "                   val_roc_auc_lgb if 'val_roc_auc_lgb' in globals() else 0,\n",
        "                   val_roc_auc_final_lgb)\n",
        "\n",
        "if val_roc_auc_final_lgb == best_val_auc:\n",
        "    print(\"\\nОптимізована модель LightGBM показала найкращий результат на валідаційному наборі.\")\n",
        "elif val_roc_auc_final == best_val_auc:\n",
        "    print(\"\\nОптимізована модель XGBoost показала найкращий результат на валідаційному наборі.\")\n",
        "elif val_roc_auc_lgb == best_val_auc:\n",
        "    print(\"\\nПочаткова модель LightGBM показала найкращий результат на валідаційному наборі.\")\n",
        "elif val_roc_auc_xgb == best_val_auc:\n",
        "     print(\"\\nПочаткова модель XGBoost показала найкращий результат на валідаційному наборі.\")"
      ],
      "metadata": {
        "id": "cfMQKA4D47Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24dc387b-7309-477a-ea5a-bc53d42d8a04"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 10%|█         | 1/10 [00:02<00:23,  2.63s/trial, best loss: -0.9272590712668909]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 20%|██        | 2/10 [00:03<00:13,  1.63s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012754 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 30%|███       | 3/10 [00:06<00:15,  2.17s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 40%|████      | 4/10 [00:07<00:11,  1.84s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008959 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 50%|█████     | 5/10 [00:09<00:08,  1.79s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000951 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 60%|██████    | 6/10 [00:10<00:05,  1.40s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            " 70%|███████   | 7/10 [00:10<00:03,  1.07s/trial, best loss: -0.9297201454146375]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005410 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 80%|████████  | 8/10 [00:11<00:01,  1.15trial/s, best loss: -0.9316839289388846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008516 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            " 90%|█████████ | 9/10 [00:12<00:01,  1.16s/trial, best loss: -0.9316839289388846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "100%|██████████| 10/10 [00:16<00:00,  1.66s/trial, best loss: -0.9316839289388846]\n",
            "\n",
            "Найкращі гіперпараметри для LightGBM: {'colsample_bytree': np.float64(0.9891165509011955), 'learning_rate': np.float64(0.06399754217368746), 'max_depth': np.float64(10.0), 'min_child_samples': np.float64(10.0), 'n_estimators': np.float64(150.0), 'num_leaves': np.float64(35.0), 'reg_alpha': np.float64(0.5690730597034503), 'reg_lambda': np.float64(0.02730340452383191), 'subsample': np.float64(0.9462695183317298)}\n",
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Warning] categorical_feature is set=1,3,4, categorical_column=1,3,4 will be ignored. Current value: categorical_feature=1,3,4\n",
            "[LightGBM] [Info] Number of positive: 2442, number of negative: 9558\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000897 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1571\n",
            "[LightGBM] [Info] Number of data points in the train set: 12000, number of used features: 12\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203500 -> initscore=-1.364561\n",
            "[LightGBM] [Info] Start training from score -1.364561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py:2137: UserWarning: categorical_feature keyword has been found in `params` and will be ignored.\n",
            "Please use categorical_feature argument of the Dataset constructor to pass this parameter.\n",
            "  _log_warning(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUROC on training set (LightGBM with Hyperopt): 0.9920\n",
            "AUROC on validation set (LightGBM with Hyperopt): 0.9317\n",
            "\n",
            "Висновки щодо моделі LightGBM з Hyperopt:\n",
            "Модель, можливо, має високу дисперсію (high variance), оскільки якість на тренувальному наборі значно вища, ніж на валідаційному.\n",
            "\n",
            "Порівняння з попередніми моделями:\n",
            "AUROC на валідаційному наборі XGBoost (без Hyperopt): 0.9323\n",
            "AUROC на валідаційному наборі XGBoost (з Hyperopt): 0.9365\n",
            "AUROC на валідаційному наборі LightGBM (без Hyperopt): 0.9323\n",
            "AUROC на валідаційному наборі LightGBM (з Hyperopt): 0.9317\n",
            "\n",
            "Оптимізована модель XGBoost показала найкращий результат на валідаційному наборі.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Оберіть модель з експериментів в цьому ДЗ і зробіть новий `submission` на Kaggle та додайте код для цього і скріншот скора на публічному лідерборді.\n",
        "  \n",
        "  **Напишіть коментар, чому ви обрали саме цю модель?**\n",
        "\n",
        "  І я вас вітаю - це останнє завдання з цим набором даних 💪 На цьому етапі корисно проаналізувати, які моделі показали себе найкраще і подумати, чому."
      ],
      "metadata": {
        "id": "XArADR2CG8VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "try:\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: test.csv not found. Please make sure the file is in the correct directory.\")\n",
        "    test_df = None\n",
        "\n",
        "if test_df is not None:\n",
        "    # Prepare test data: select input columns and convert categorical features\n",
        "    test_inputs = test_df[input_cols].copy()\n",
        "\n",
        "    for col in categorical_cols:\n",
        "         if col in test_inputs.columns:\n",
        "              test_inputs[col] = test_inputs[col].astype('category')\n",
        "\n",
        "\n",
        "    # Make predictions on the test data using the best model (optimized XGBoost)\n",
        "    # Ensure the best model variable name matches the one from the previous step\n",
        "    # In this case, it's 'final_clf' from cell WhR1g9B4433r\n",
        "    if 'final_clf' in globals():\n",
        "        test_predictions = final_clf.predict_proba(test_inputs)[:, 1]\n",
        "\n",
        "        # Create the submission DataFrame\n",
        "        submission_df = pd.DataFrame({'id': test_df['id'], 'Exited': test_predictions})\n",
        "\n",
        "        # Save the submission file\n",
        "        submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "        print(\"Submission file 'submission.csv' created successfully!\")\n",
        "        print(submission_df.head())\n",
        "    else:\n",
        "        print(\"Error: Optimized XGBoost model ('final_clf') not found. Please ensure the previous cell ran successfully.\")"
      ],
      "metadata": {
        "id": "COIjJH9f5SSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deae102b-43d4-4ae8-9807-9d65760ea372"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file 'submission.csv' created successfully!\n",
            "      id    Exited\n",
            "0  15000  0.078740\n",
            "1  15001  0.017630\n",
            "2  15002  0.070709\n",
            "3  15003  0.509270\n",
            "4  15004  0.038327\n"
          ]
        }
      ]
    }
  ]
}